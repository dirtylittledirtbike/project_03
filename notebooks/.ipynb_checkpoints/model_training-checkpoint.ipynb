{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from urlextract import URLExtract\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle \n",
    "\n",
    "from src.model_insights import get_word_covariance, get_class_features\n",
    "\n",
    "extractor = URLExtract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('/Users/collinswestnedge/programming/Metis_Online/project_03/data/jigsaw-toxic-comment-classification-challenge/train.csv')\n",
    "test_df_labels = pd.read_csv('/Users/collinswestnedge/programming/Metis_Online/project_03/data/jigsaw-toxic-comment-classification-challenge/test_labels.csv')\n",
    "test_df = pd.read_csv('/Users/collinswestnedge/programming/Metis_Online/project_03/data/jigsaw-toxic-comment-classification-challenge/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing the -1 labels in test labels and \n",
    "# and joining it with the test.csv \n",
    "test_labels_temp = test_df_labels.replace(-1,np.nan)\n",
    "test_labels_clean = test_labels_temp.dropna()\n",
    "test_data = test_df.merge(test_labels_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    \n",
    "    def replace_urls(x):\n",
    "        urls = extractor.find_urls(x)\n",
    "        if urls:\n",
    "            x_new = replace_urls(x.replace(urls[0],''))\n",
    "            return x_new\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "    data['comment_text'] = data.comment_text.map(lambda x: replace_urls(x))\n",
    "    #get rid of duplicate letters just trying this out may comment out later\n",
    "    data['comment_text'] = data.comment_text.map(lambda x: re.sub(r'(.)\\1{2,}', '', str(x).lower()))\n",
    "    # removing indents\n",
    "    data['comment_text'] = data.comment_text.map(lambda x: re.sub('\\\\n',' ',str(x)))\n",
    "    # remove weird user occurence \n",
    "    data['comment_text'] = data.comment_text.map(lambda x: re.sub(\"\\[\\[User.*\",'',str(x)))\n",
    "    # remove ip address\n",
    "    data['comment_text'] = data.comment_text.map(lambda x: re.sub(\"\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\",'',str(x)))\n",
    "    \n",
    "    return data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import plot_roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(classifier, X_train, y_train, X_test, y_test, plot_curve=False):\n",
    "    \n",
    "    # literally making this for my own practice \n",
    "    # i know theres a lot quicker/simpler ways\n",
    "    \n",
    "    model = classifier\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    actuals = y_test\n",
    "    \n",
    "    print('-'*20 + ' ' + type(model).__name__  + ' ' + '-'*20)\n",
    "        \n",
    "    err_df = pd.DataFrame({'pred':preds, 'actual':actuals})\n",
    "\n",
    "    TP = err_df.actual[(err_df.actual==1) & (err_df.pred==1)].count()\n",
    "    print('TP: ', TP)\n",
    "    # False Positives:\n",
    "    FP = err_df.actual[(err_df.actual==0) & (err_df.pred==1)].count()\n",
    "    print('FP: ', FP)\n",
    "    # #True Negatives:\n",
    "    TN = err_df.actual[(err_df.actual==0) & (err_df.pred==0)].count()\n",
    "    print('TN: ', TN)\n",
    "    #False Negatives:\n",
    "    FN = err_df.actual[(err_df.actual==1) & (err_df.pred==0)].count()\n",
    "    print('FN: ', FN)\n",
    "    print()\n",
    "\n",
    "    precision = TP/(TP+FP)\n",
    "    recall =  TP/(TP+FN)\n",
    "    print('Precision:', precision)\n",
    "    print('Recall:', recall)\n",
    "    print('Accuracy:', model.score(X_test, y_test))\n",
    "    print('F1 Score:', 2*((precision*recall)/(precision+recall)))\n",
    "    \n",
    "    if plot_curve:\n",
    "        print('Area Under ROC Curve:', roc_auc_score(y_test, model.predict_proba(X_test)[:,1]))\n",
    "        fig, ax = plt.subplots(figsize=(6,4))\n",
    "        test_disp = plot_roc_curve(model, X_test, y_test, ax=ax, color='red', linewidth=3)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clean = preprocess(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_clean = preprocess(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------- playing with count vectorizer ------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from nltk import RegexpTokenizer\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# found sorted/ the highest coefficients for both labels and then\n",
    "# looked where the the difference between the \n",
    "new_stop_words = ['anything',\n",
    " 'person',\n",
    " 'day',\n",
    " 'even',\n",
    " 'wrong',\n",
    " 'said',\n",
    " 'personal',\n",
    " 'message',\n",
    " 'site',\n",
    " 'vandalism',\n",
    " 'thing',\n",
    " 'keep',\n",
    " 'right',\n",
    " 'really',\n",
    " 'know',\n",
    " 'make',\n",
    " 'back',\n",
    " 'let',\n",
    " 'put',\n",
    " 'take',\n",
    " 'better',\n",
    " 'something',\n",
    " 'mean',\n",
    " 'say',\n",
    " 'want',\n",
    " 'never',\n",
    " 'think',\n",
    " 'fact',\n",
    " 'time',\n",
    " 'attack',\n",
    " 'warning',\n",
    " 'world',\n",
    " 'blocked',\n",
    " 'still',\n",
    " 'got',\n",
    " 'edits',\n",
    " 'someone',\n",
    " 'way',\n",
    " 'people',\n",
    " 'going',\n",
    " 'well',\n",
    " 'come',\n",
    " 'user',\n",
    " 'one',\n",
    " 'like',\n",
    " 'look',\n",
    " 'change',\n",
    " 'much',\n",
    " 'good',\n",
    " 'tell',\n",
    " 'day',\n",
    " 'even',\n",
    " 'said',\n",
    " 'vandalism',\n",
    " 'thing',\n",
    " 'keep',\n",
    " 'right',\n",
    " 'really',\n",
    " 'know',\n",
    " 'make',\n",
    " 'back',\n",
    " 'let',\n",
    " 'put',\n",
    " 'take',\n",
    " 'better',\n",
    " 'something',\n",
    " 'mean',\n",
    " 'say',\n",
    " 'want',\n",
    " 'think',\n",
    " 'fact',\n",
    " 'time',\n",
    " 'blocked',\n",
    " 'still',\n",
    " 'edits',\n",
    " 'someone',\n",
    " 'way',\n",
    " 'people',\n",
    " 'going',\n",
    " 'well',\n",
    " 'word',\n",
    " 'user',\n",
    " 'one',\n",
    " 'like',\n",
    " 'look',\n",
    " 'change',\n",
    " 'much',\n",
    " 'good',\n",
    " 'comment',\n",
    " 'read',\n",
    " 'many',\n",
    " 'reason',\n",
    " 'sorry',\n",
    " 'page',\n",
    " 'need',\n",
    " 'made',\n",
    " 'edit',\n",
    " 'place',\n",
    " 'name',\n",
    " 'block',\n",
    " 'wikipedia',\n",
    " 'wiki']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import RegexpTokenizer\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words_complete = stopwords.words('english') + new_stop_words\n",
    "\n",
    "# pickling stop words so i can do this in different notebook\n",
    "# unfortunately pickling a class is hard so im going to have to\n",
    "# copy paste the tokenizer class over \n",
    "\n",
    "with open('stop_words.pickle', 'wb') as file:\n",
    "#     pickle.dump(my_tokenizer, file)\n",
    "    pickle.dump(stop_words_complete, file)\n",
    "    \n",
    "class Tokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.pt = PorterStemmer()\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "        self.tk = RegexpTokenizer(r'\\b[a-zA-Z]{3,}\\b')\n",
    "        self.stpwrd = set(stop_words_complete)\n",
    "        \n",
    "    def __call__(self, doc):\n",
    "        return [self.wnl.lemmatize(t) for t in self.tk.tokenize(doc) if not t in self.stpwrd]\n",
    "\n",
    "my_tokenizer = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.sentiment_neutral.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# X, y = train_clean['comment_text'], train_clean['toxic']\n",
    "# # X, y = train_df['text'], train_df['sentiment_positive']\n",
    "\n",
    "# # X, y = train_balanced['comment_text'], train_balanced['toxic']\n",
    "\n",
    "# metrics = []\n",
    "# skf = StratifiedKFold(n_splits=5)\n",
    "# for train_index, test_index in skf.split(X, y):\n",
    "    \n",
    "#     X_train, X_val = X.iloc[train_index], X.iloc[test_index]\n",
    "#     y_train, y_val = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    \n",
    "#     vect = TfidfVectorizer(\n",
    "\n",
    "# #                           lowercase = True,\n",
    "# #                           token_pattern=None,\n",
    "# #                           tokenizer=my_tokenizer,\n",
    "# #                           ngram_range=(1, 1), \n",
    "# #                           max_features=8000\n",
    "        \n",
    "#                           lowercase = True,\n",
    "#                           strip_accents='unicode',\n",
    "#                           stop_words=stop_words_complete,\n",
    "#                           analyzer='word',\n",
    "#                           token_pattern = r'\\b[a-zA-Z]{3,}\\b',\n",
    "#                           ngram_range = (1,1),\n",
    "#                           max_features=8000\n",
    "#                           )\n",
    "    \n",
    "#     X_train_vect = vect.fit_transform(X_train)\n",
    "#     X_val_vect = vect.transform(X_val)\n",
    "    \n",
    "#     nb = MultinomialNB()\n",
    "#     nb.fit(X_train_vect, y_train)\n",
    "\n",
    "#     y_pred_class = nb.predict(X_val_vect)\n",
    "#     metrics.append(accuracy_score(y_val, y_pred_class))\n",
    "\n",
    "# metrics = np.array(metrics)\n",
    "# print('Mean accuracy: ', np.mean(metrics, axis=0))\n",
    "# print('Std for accuracy: ', np.std(metrics, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def vectorize_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X, y = train_clean['comment_text'], train_clean['toxic']\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.20, random_state=1)\n",
    "\n",
    "vect = TfidfVectorizer(\n",
    "\n",
    "                      lowercase = True,\n",
    "                      token_pattern=None,\n",
    "                      tokenizer=my_tokenizer,\n",
    "                      ngram_range=(1, 1),\n",
    "                      max_features=8000\n",
    "\n",
    "                      )\n",
    "\n",
    "X_train_vect = vect.fit_transform(X_train)\n",
    "X_val_vect = vect.transform(X_val)\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_vect, y_train)\n",
    "nb.score(X_val_vect, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('vectorizer.pickle', 'wb') as file:\n",
    "#     # pickling vectorizer and vectorized data\n",
    "#     pickle.dump(vect, file)\n",
    "#     pickle.dump(X_train_vect, file)\n",
    "#     pickle.dump(X_val_vect, file)\n",
    "    \n",
    "#     # pickling fitted model\n",
    "#     pickle.dump(nb, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_metrics(MultinomialNB(), X_train_vect, y_train, X_val_vect, y_val, plot_curve=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, cov = get_word_covariance(vect, nb, n=5, top=True)\n",
    "temp = df.reset_index()\n",
    "filtered_temp = temp.sort_values(by=['toxic_coefs'], ascending=False)\n",
    "filtered_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, cov = get_word_covariance(vect, nb, n=2000)\n",
    "temp = df.reset_index()\n",
    "filtered_temp = temp.sort_values(by=['non_toxic_coefs'], ascending=False)\n",
    "filtered_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# get highest coefficients for model\n",
    "# sort dataframe by highest toxic coefficients and THEN\n",
    "# look where coefficients have small difference for both labels\n",
    "# and use this to create stop words\n",
    "\n",
    "df, cov = get_word_covariance(vect, nb, n=100)\n",
    "temp = df.reset_index()\n",
    "filtered_temp = temp.sort_values(by=['toxic_coefs'], ascending=False)\n",
    "filtered_temp = filtered_temp[(filtered_temp.non_toxic_coefs.notnull()) & (filtered_temp.toxic_coefs.notnull())].head(100).copy()\n",
    "filtered_temp['coefficient_diff'] = (filtered_temp['non_toxic_coefs'] - filtered_temp['toxic_coefs'])**2\n",
    "filtered_temp.sort_values(by=['coefficient_diff']).head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, cov = get_word_covariance(vect, nb, n=100)\n",
    "temp = df.reset_index()\n",
    "filtered_temp = temp.sort_values(by=['non_toxic_coefs'], ascending=False)\n",
    "filtered_temp = filtered_temp[(filtered_temp.non_toxic_coefs.notnull()) & (filtered_temp.toxic_coefs.notnull())].head(100).copy()\n",
    "filtered_temp['coefficient_diff'] = (filtered_temp['non_toxic_coefs'] - filtered_temp['toxic_coefs'])**2\n",
    "filtered_temp.sort_values(by=['coefficient_diff']).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = get_word_covariance(vect, nb, n=1000, top=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "\n",
    "topics = 20\n",
    "cols = ['topic' + str(i+1) for i in range(topics)]\n",
    "nmf = NMF(n_components=topics, random_state=1,\n",
    "          alpha=.1, l1_ratio=.5).fit(X_train_vect)\n",
    "\n",
    "topic_df = pd.DataFrame(nmf.components_, index=cols, columns=vect.get_feature_names()).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        message = \"Topic #%d: \" % topic_idx\n",
    "        message += \" \".join([feature_names[i]\n",
    "                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        print(message)\n",
    "    print()\n",
    "\n",
    "tfidf_feature_names = vect.get_feature_names()\n",
    "n_top_words = 20\n",
    "print_top_words(nmf, tfidf_feature_names, n_top_words)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg, pos = get_class_features(vect, nb, n=10, top=True)\n",
    "topic_formatted = topic_df.T[pos].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def graph_topic(words,topic=[1,2]):\n",
    "    topic_formatted = topic_df.T[words].T\n",
    "    if len(topic) == 2:\n",
    "        cols = ['topic'+str(val) for val in topic]\n",
    "        plt.figure(figsize=[5,12])\n",
    "        plt.barh(topic_formatted.index, topic_formatted[cols[0]])\n",
    "        plt.barh(topic_formatted.index, topic_formatted[cols[1]])\n",
    "    else:\n",
    "        print('redo')\n",
    "# plt.xticks(rotation=90);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_topic(pos,[1,17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD, PCA\n",
    "\n",
    "topics = 5\n",
    "cols = ['topic' + str(i+1) for i in range(topics)]\n",
    "svd = TruncatedSVD(n_components=topics)\n",
    "lsa = svd.fit_transform(X_vect)\n",
    "lsa_df = pd.DataFrame(lsa, columns=cols)\n",
    "lsa_df['document'] = train_df['comment_text']\n",
    "lsa_df['toxic'] = train_df.toxic\n",
    "lsa_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i think i may be indexing into these wrong look/fix later\n",
    "neg, pos = get_class_features(vect, nb, n=20, top=True, indices=True)\n",
    "lsa_df.iloc[neg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(svd.components_, index=cols, columns=vect.get_feature_names()).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca = PCA(2)\n",
    "# X = pca.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, cov = get_word_covariance(vect, nb, n=1000, top=True)\n",
    "# cov['hate'].sort_values(ascending=False).to_frame()\n",
    "cov['please'].sort_values(ascending=False).to_frame()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# testing = train_df[train_df['comment_text'].str.contains('nazi') & (train_df.toxic==1)].comment_text.values[6]\n",
    "# print(testing)\n",
    "# print('-'*100)\n",
    "# tokenized_test = np.array(my_tokenizer(testing), dtype=np.object)\n",
    "# idx = np.where(tokenized_test=='nazi')[0]\n",
    "\n",
    "# if len(idx) > 0:\n",
    "#     for item in idx:\n",
    "#         if item > 0:\n",
    "#             print(tokenized_test[item-1])\n",
    "#         print(tokenized_test[item])\n",
    "#         if item < len(tokenized_test) -1:\n",
    "#             print(tokenized_test[item+1])\n",
    "\n",
    "\n",
    "# testing = train_df[train_df['comment_text'].str.contains('nazi')&(train_df.toxic==0)].comment_text.values[3]\n",
    "# print(testing[-700::])\n",
    "# print('-'*100)\n",
    "# tokenized_test = np.array(my_tokenizer(testing), dtype=np.object)\n",
    "# idx = np.where(tokenized_test=='nazi')[0]\n",
    "\n",
    "# if len(idx) > 0:\n",
    "#     for item in idx:\n",
    "#         if item > 0:\n",
    "#             print(tokenized_test[item-1])\n",
    "#         print(tokenized_test[item])\n",
    "#         if item < len(tokenized_test) -1:\n",
    "#             print(tokenized_test[item+1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_holdout = test_clean.comment_text\n",
    "y_holdout = test_clean.toxic\n",
    "\n",
    "vect = TfidfVectorizer(\n",
    "                      lowercase = True,\n",
    "                      token_pattern=None,\n",
    "                      tokenizer=my_tokenizer,\n",
    "                      ngram_range=(1, 1),\n",
    "                      max_features=8000\n",
    "                      )\n",
    "\n",
    "X_train_vect = vect.fit_transform(X)\n",
    "X_holdout_vect = vect.transform(X_holdout)\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_vect, y)\n",
    "nb.score(X_holdout_vect, y_holdout)\n",
    "\n",
    "# pickling the vectorized data from training set so we can do \n",
    "# eda in another notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('vectorizer.pickle', 'wb') as file:\n",
    "# #     pickling trained and vectorized data\n",
    "#     pickle.dump(vect, file)\n",
    "#     pickle.dump(X_train_vect, file)\n",
    "#     pickle.dump(X_holdout_vect, file)\n",
    "    \n",
    "#     # pickling fitted model\n",
    "#     pickle.dump(nb, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_metrics(MultinomialNB(), X_train_vect, y, X_holdout_vect, y_holdout, plot_curve=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TP:  3588\n",
    "# FP:  1579\n",
    "# TN:  56309\n",
    "# FN:  2502\n",
    "\n",
    "# Precision: 0.694406812463712\n",
    "# Recall: 0.5891625615763547\n",
    "# Accuracy: 0.9362124480290099\n",
    "# F1 Score: 0.637470018655059\n",
    "# Area Under ROC Curve: 0.9470568584508582"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
